{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/07/11\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yaml\n",
    "with open('config.yml') as f:\n",
    "    config = yaml.load(f)\n",
    "\n",
    "dwp = config['dcsedwp']\n",
    "dcgis = config['dcgisprd']\n",
    "\n",
    "import datetime as dt     \n",
    "date = dt.datetime.today().strftime(\"%Y/%m/%d\")\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DCGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "dsn_tns = cx_Oracle.makedsn(dcgis['host'], dcgis['port'], service_name=dcgis['service_name'])\n",
    "dcgisprd = cx_Oracle.connect(dcgis['username'], dcgis['password'], dsn_tns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blocks = gpd.read_file('data/Census_Blocks__2010.geojson')\n",
    "blocks = blocks[['GEOID', 'BLOCK', 'BLKGRP', 'P0010001', 'SqMiles', 'ACRES', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blks = blocks[['GEOID', 'P0010001', 'SqMiles']].set_index('GEOID')\n",
    "blks['pop_density'] = blks['P0010001']*1.0/blks['SqMiles']\n",
    "blks['tot_pop'] = blks['P0010001']\n",
    "blks = blks.drop(['P0010001', 'SqMiles'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units = pd.read_sql('''\n",
    "        select \n",
    "        a.address_id,\n",
    "        count(*) as NUM_UNITS\n",
    "        from MARDBA.VW_ADDRESS a\n",
    "        left join MARDBA.VW_ADDRESSUNIT b on a.address_id = b.address_id\n",
    "        where a.status='ACTIVE' \n",
    "        group by a.address_id\n",
    "    ''', dcgisprd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "address = pd.read_sql('''\n",
    "        select \n",
    "        a.address_id,\n",
    "        case when res_type = 'RESIDENTIIAL' then 'RESIDENTIAL' else res_type end as RES_TYPE,\n",
    "        a.latitude,\n",
    "        a.longitude\n",
    "        from MARDBA.VW_ADDRESS a\n",
    "        where a.status='ACTIVE' \n",
    "    ''', dcgisprd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264191    1\n",
       "26022     1\n",
       "275884    1\n",
       "265643    1\n",
       "263594    1\n",
       "269737    1\n",
       "267688    1\n",
       "290215    1\n",
       "294309    1\n",
       "81293     1\n",
       "Name: ADDRESS_ID, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_units = address.merge(units, how='left', on='ADDRESS_ID')\n",
    "## Check for duplicates after join\n",
    "address_units.ADDRESS_ID.value_counts(ascending=False).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create geometry for MAR data\n",
    "geometry = [Point(xy) for xy in zip(address_units.LONGITUDE.apply(float), address_units.LATITUDE.apply(float))]\n",
    "crs = {'init': 'epsg:4326'}\n",
    "points = gpd.GeoDataFrame(address_units, crs=crs, geometry=geometry)\n",
    "\n",
    "address_blocks = gpd.sjoin(blocks, points, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_blocks = blks\n",
    "for r in address_blocks[address_blocks.RES_TYPE.isnull()==False].RES_TYPE.unique():\n",
    "    r_units = address_blocks[address_blocks.RES_TYPE==r]\n",
    "    num_units = pd.DataFrame(r_units.groupby('GEOID').NUM_UNITS.sum())\n",
    "    avg_units = pd.DataFrame(r_units.groupby('GEOID').NUM_UNITS.mean())\n",
    "    med_units = pd.DataFrame(r_units.groupby('GEOID').NUM_UNITS.median())\n",
    "    min_units = pd.DataFrame(r_units.groupby('GEOID').NUM_UNITS.count())\n",
    "    max_units = pd.DataFrame(r_units.groupby('GEOID').NUM_UNITS.count())\n",
    "    \n",
    "    num_units.columns = ['num_'+r.lower().replace(' ', '_')]\n",
    "    avg_units.columns = ['avg_'+r.lower().replace(' ', '_')]\n",
    "    med_units.columns = ['med_'+r.lower().replace(' ', '_')]\n",
    "    min_units.columns = ['min_'+r.lower().replace(' ', '_')]\n",
    "    max_units.columns = ['max_'+r.lower().replace(' ', '_')]\n",
    "    \n",
    "    unit_blocks = unit_blocks.merge(num_units, how='left', left_index=True, right_index=True)\n",
    "    unit_blocks = unit_blocks.merge(avg_units, how='left', left_index=True, right_index=True)\n",
    "    unit_blocks = unit_blocks.merge(med_units, how='left', left_index=True, right_index=True)\n",
    "    unit_blocks = unit_blocks.merge(min_units, how='left', left_index=True, right_index=True)\n",
    "    unit_blocks = unit_blocks.merge(max_units, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "unit_blocks = unit_blocks.drop(['pop_density', 'tot_pop'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_blocks.to_csv('data/address_units_to_blocks.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cama_res = pd.read_sql('''\n",
    "    select\n",
    "        ssl,\n",
    "        bldg_num,\n",
    "        ayb,\n",
    "        eyb,\n",
    "        case when ayb is null then to_number(substr(to_char(eyb),0,4))\n",
    "            when ayb < 1754 then to_number(substr(to_char(eyb),0,4))\n",
    "            when length(ayb) > 4 then to_number(substr(to_char(ayb),0,4))\n",
    "            when ayb > 2017 then to_number(substr(to_char(ayb),0,4))\n",
    "            else to_number(substr(to_char(ayb),0,4)) end as year_built,\n",
    "        case when eyb is null then ayb else eyb end as alt_year_built,        \n",
    "        yr_rmdl,\n",
    "        cndtn_d\n",
    "    from DCGIS.VW_CAMARES_OWNERPLY\n",
    "    where ssl is not null and cndtn_d <> 'Default'\n",
    "''', dcgisprd)\n",
    "\n",
    "cama_res['CNDTN_D'] = cama_res.CNDTN_D.str.replace(' ', '')\n",
    "cndtn = pd.DataFrame(pd.get_dummies(cama_res.CNDTN_D, prefix='ssl_cndtn'), index=cama_res.index)\n",
    "cama_res = cama_res.merge(cndtn, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssl_coords = pd.read_sql('''\n",
    "    select\n",
    "        ssl,\n",
    "        median(latitude) as latitude,\n",
    "        median(longitude) as longitude\n",
    "    from MARDBA.VW_ADDRESS\n",
    "    where latitude is not null and longitude is not null\n",
    "        and ssl is not null\n",
    "    group by ssl\n",
    "''', dcgisprd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cama = ['SSL', 'YEAR_BUILT', 'ssl_cndtn_Average', 'ssl_cndtn_Excellent', 'ssl_cndtn_Fair', 'ssl_cndtn_Good', 'ssl_cndtn_Poor', 'ssl_cndtn_VeryGood']\n",
    "ssl_cama = ssl_coords.merge(cama_res[cama], how='left', on='SSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create geometry for CAMA Data\n",
    "geometry = [Point(xy) for xy in zip(ssl_cama.LONGITUDE.apply(float), ssl_cama.LATITUDE.apply(float))]\n",
    "crs = {'init': 'epsg:4326'}\n",
    "points = gpd.GeoDataFrame(ssl_cama, crs=crs, geometry=geometry)\n",
    "\n",
    "camares_blocks = gpd.sjoin(blocks, points, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_year_built = pd.DataFrame(camares_blocks.groupby('GEOID').YEAR_BUILT.mean())\n",
    "med_year_built = pd.DataFrame(camares_blocks.groupby('GEOID').YEAR_BUILT.median())\n",
    "min_year_built = pd.DataFrame(camares_blocks.groupby('GEOID').YEAR_BUILT.min())\n",
    "max_year_built = pd.DataFrame(camares_blocks.groupby('GEOID').YEAR_BUILT.max())\n",
    "\n",
    "avg_year_built.columns = ['avg_year_built']\n",
    "med_year_built.columns = ['med_year_built']\n",
    "min_year_built.columns = ['min_year_built']\n",
    "max_year_built.columns = ['max_year_built']\n",
    "\n",
    "ssl_g = ['ssl_cndtn_Average', 'ssl_cndtn_Excellent', 'ssl_cndtn_Fair', 'ssl_cndtn_Good', 'ssl_cndtn_Poor', 'ssl_cndtn_VeryGood']\n",
    "avg_grade = pd.DataFrame(camares_blocks.groupby('GEOID')[ssl_g].mean())\n",
    "avg_grade.columns = ssl_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camares_blks = blks\n",
    "camares_blks = camares_blks.merge(avg_year_built, how='left', left_index=True, right_index=True)\n",
    "camares_blks = camares_blks.merge(med_year_built, how='left', left_index=True, right_index=True)\n",
    "camares_blks = camares_blks.merge(min_year_built, how='left', left_index=True, right_index=True)\n",
    "camares_blks = camares_blks.merge(max_year_built, how='left', left_index=True, right_index=True)\n",
    "camares_blks = camares_blks.merge(avg_grade, how='left', left_index=True, right_index=True)\n",
    "camares_blks = camares_blks.fillna(0)\n",
    "camares_blks = camares_blks.drop(['pop_density', 'tot_pop'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commercial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cama_comm = pd.read_sql('''\n",
    "    select\n",
    "        ssl,\n",
    "        bldg_num,\n",
    "        ayb,\n",
    "        eyb,\n",
    "        case when ayb is null then to_number(substr(to_char(eyb),0,4))\n",
    "            when ayb < 1754 then to_number(substr(to_char(eyb),0,4))\n",
    "            when ayb > 2017 then to_number(substr(to_char(eyb),0,4))\n",
    "            else to_number(substr(to_char(ayb),0,4)) end as year_built,\n",
    "        case when eyb is null then ayb else eyb end as alt_year_built,        \n",
    "        yr_rmdl,\n",
    "        grade_d as cndtn_d\n",
    "    from DCGIS.VW_CAMACOMM_OWNERPLY\n",
    "    where ssl is not null and grade_d <> 'Default'\n",
    "''', dcgisprd)\n",
    "\n",
    "cama_comm['CNDTN_D'] = cama_comm.CNDTN_D.str.replace('+', '')\n",
    "cama_comm['CNDTN_D'] = cama_comm.CNDTN_D.str.replace(' ', '')\n",
    "cndtn = pd.DataFrame(pd.get_dummies(cama_comm.CNDTN_D, prefix='ssl_cndtn'), index=cama_res.index)\n",
    "cama_comm = cama_comm.merge(cndtn, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cama = ['SSL', 'YEAR_BUILT', 'ssl_cndtn_Average', 'ssl_cndtn_Excellent', 'ssl_cndtn_Fair', 'ssl_cndtn_Good', 'ssl_cndtn_Poor', 'ssl_cndtn_VeryGood']\n",
    "ssl_camacomm = ssl_coords.merge(cama_comm[cama], how='left', on='SSL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create geometry for CAMA Commercial Data\n",
    "geometry = [Point(xy) for xy in zip(ssl_camacomm.LONGITUDE.apply(float), ssl_camacomm.LATITUDE.apply(float))]\n",
    "crs = {'init': 'epsg:4326'}\n",
    "points = gpd.GeoDataFrame(ssl_camacomm, crs=crs, geometry=geometry)\n",
    "\n",
    "camacomm_blocks = gpd.sjoin(blocks, points, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_year_built = pd.DataFrame(camacomm_blocks.groupby('GEOID').YEAR_BUILT.mean())\n",
    "med_year_built = pd.DataFrame(camacomm_blocks.groupby('GEOID').YEAR_BUILT.median())\n",
    "min_year_built = pd.DataFrame(camacomm_blocks.groupby('GEOID').YEAR_BUILT.min())\n",
    "max_year_built = pd.DataFrame(camacomm_blocks.groupby('GEOID').YEAR_BUILT.max())\n",
    "\n",
    "avg_year_built.columns = ['avg_year_built']\n",
    "med_year_built.columns = ['med_year_built']\n",
    "min_year_built.columns = ['min_year_built']\n",
    "max_year_built.columns = ['max_year_built']\n",
    "\n",
    "ssl_g = ['ssl_cndtn_Average', 'ssl_cndtn_Excellent', 'ssl_cndtn_Fair', 'ssl_cndtn_Good', 'ssl_cndtn_Poor', 'ssl_cndtn_VeryGood']\n",
    "avg_grade = pd.DataFrame(camacomm_blocks.groupby('GEOID')[ssl_g].mean())\n",
    "avg_grade.columns = ssl_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camacomm_blks = blks\n",
    "camacomm_blks = camacomm_blks.merge(avg_year_built, how='left', left_index=True, right_index=True)\n",
    "camacomm_blks = camacomm_blks.merge(med_year_built, how='left', left_index=True, right_index=True)\n",
    "camacomm_blks = camacomm_blks.merge(min_year_built, how='left', left_index=True, right_index=True)\n",
    "camacomm_blks = camacomm_blks.merge(max_year_built, how='left', left_index=True, right_index=True)\n",
    "camacomm_blks = camacomm_blks.merge(avg_grade, how='left', left_index=True, right_index=True)\n",
    "camacomm_blks = camacomm_blks.fillna(0)\n",
    "camacomm_blks = camacomm_blks.drop(['pop_density', 'tot_pop'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine CAMA Res and Comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cama_blks = camares_blks.merge(camacomm_blks, how='outer', left_index=True, right_index=True, suffixes=['_res', '_comm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cama_blks.to_csv('data/cama_to_blocks.csv.gz', compression = 'gzip')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
